%begin-include
{\color{blue} Simple description of the content of this chapter}.

\section{Model ranking using Marginal Likelihood}
% Simple explanation of this model ranking
% Describe the likelihood function 
% However, this is very hard to calculate
% It is possible to apply an Importance Sampling Estimator {cite 
% Newton and Raftery}. However, it was showed on {cite girolami again}
% that these methods do not perform well.
% Then it was proposed to use Thermodynamic Integration. Make it clear 
% that this allows us to create some estimators.
% Subsection - Thermodynamic Integration
% -> explain how to derive it
%   -> name what is the power posterior
% -> include here: how to estimate it?
% Subsection - Estimation of the Marginal Likelihood 
% -> We need to find samples of the posteriors
% -> Explain that we use the methodology of Xuan
% -> We use three Metropolis-Hastings
% -> A first burn-in step with jumps independent for each single 
% parameter. Adaptive Metropolis Hastings
% -> A second using a Variance-Covariance Matrix
% -> A third using populational MCMC
The marginal likelihood of an experiment measurement $D$ being 
reproduced by a model $M$, $p (D | M)$, can be used as a model ranking 
metric as it determines which model makes the experimental observations 
more likely to happen. Before defining how to calculate the marginal 
likelihood, we must define what the likelihood function is. To calculate 
the likelihood $p (D | M, \theta)$, we must understand that conditioning 
the observation to the model and parameters means that in 
the probability space from which $D$ is taken, the model $M$ is the 
``real'' model and it has the parameter values of $\theta$; i.e. the 
model $M$ with parameters $\theta$ controls the behaviour of the system 
from which $D$ was observed. Then, assuming that the observations have a 
Gaussian error, and that they are taken in a time series of $m$ time 
steps, we can define the likelihood as:
\begin{equation}
    p (D | M, \theta) = p_{\mathcal{N}_{\left(\vec{0}, \Sigma\right)}}
        (\phi (M,\theta) - D),
\label{eq:likelihood_multivariate}
\end{equation}
where $\phi (M, \theta) \in \fieldR^m$ is the experimental measurement 
on the simulation generated by the model $M$ with parameters $\theta$,
and \smash{$p_{\mathcal{N}_{(\vec{0}, \Sigma)}} (\cdot)$} is the 
probability density function of a Multivariate Normal variable with mean 
$\vec{0}$ and covariance matrix $\Sigma$. As a matter of fact, as it is
done in the work of Xu et al., we can consider that the observation 
error is independent for each time step~\cite{Xura20}, therefore we can 
simplify~\ref{eq:likelihood_multivariate} to:
\begin{equation}
    p (D | M, \theta) = \prod_{i = 1}^m p_{\mathcal{N}_{\left(0, 
        \sigma^2\right)}} (\phi_i (M,\theta) - D_i).
\label{eq:likelihood}
\end{equation}
The $\sigma^2$ used in equation~\ref{eq:likelihood} is also a parameter
of the model, which means that, for some $k$, $\theta_k = \sigma^2$.

Now that we defined the likelihood function, we can write the marginal 
likelihood as:
\begin{equation}
    p (D | M) = \int_{\Theta} p (D | M, \theta) p (\theta | M)d\theta.
\label{eq:marginal_likelihood}
\end{equation}
However, calculating this integral analytically is only possible in 
very special cases and, usually, it would depend on knowing models for 
the distributions associated to these probability functions, which is 
generally not possible in our case.

Even though this integral is very hard to be calculated, there are 
methods that allow us to estimate its value. A straight forward method 
to estimate this integral value is using Importance Sampling 
Estimators~\cite{Newton1993}. This method uses the Monte Carlo integral 
estimation method that can estimate integrals of the form 
$\int g(\lambda) p(\lambda)d\lambda$ using the estimator:
\begin{equation*}
    \hat{I} = \sum_{i = 1}^m w_i g(\lambda_i) / \sum_{i = 1}^m w_i,
\label{eq:importance_sampling_estimator}
\end{equation*}
where $w_i = p (\lambda) / p^* (\lambda)$, and $p^*(\cdot)$ is known as 
the importance sampling function. If we set $\lambda = \theta | M$ and
use the prior ($p(\theta | M)$) or the posterior ($p(\theta | M, D)$) as 
importance sampling functions, then we would get respectively the 
estimators:
\begin{equation*}
\begin{aligned}
    \frac{1}{m} \sum_{i = 1}^m p(D|M, \theta^{(i)}) &&& 
        (\text{with } \theta^{(i)} \sim p(\theta|M)), \\
    \left(\frac{1}{m} \sum_{i = 1}^m p(D|M, \theta^{(i)})^{-1} \right)^{-1} &&&
        (\text{with } \theta^{(i)} \sim p(\theta|M)).
\end{aligned}
\end{equation*}
However, as showed by Vyshemirsky et al. (2007), these estimators might
produce very large variances and may not perform well for biochemical
model selection applications. Hence, new methods with ideas of 
thermodynamics were proposed. These methods are based on rewriting the
marginal likelihood equation using intermediate distributions of 
parameters between the prior and posterior 
distributions~\cite{Friel2008}.

% Subsection - Thermodynamic Integration
% -> explain how to derive it
%   -> name what is the power posterior
% -> include here: how to estimate it?
\subsection{Thermodynamic Integration for Marginal Likelihood}
The Thermodynamic Integration is a method that proposes to rewrite
the integral~\ref{eq:marginal_likelihood} using ideas of thermodynamics,
providing new estimators for the marginal likelihood. This method is
able to rewrite the marginal likelihood integral in a way that it 
marginalizes the likelihood through many intermediate probability spaces 
of parameters, bridging the prior and posterior distributions of 
parameters. These distributions are also called tempered distributions
or power posteriors~\cite{Friel2008}.

Given a parameter prior distribution $p (\theta | M)$ and a posterior 
distribution $p (\theta | D, M)$, then we define a power posterior 
distribution with temperature $\beta$ as:
\begin{equation*}
    p_{\beta} (\theta) = \frac{p (D | \theta, M)^\beta p(\theta | M)}
                              {z (\beta)},
\end{equation*}
where
\begin{equation*}
    z (\beta) = \int_\Theta p (D | \theta, M)^\beta p(\theta | M) 
            d\theta.
\end{equation*}
Note that when $\beta = 0$, then $p_{\beta=0} = p (\theta | M)$, the 
prior distribution of the parameters; also, when $\beta = 1$, then
\begin{equation*}
    p_{\beta=1}(\theta) = \frac{p (D | \theta, M) p(\theta | M)}
                         {z (\beta)}
                        =\frac{p (D, \theta|M)}
                              {\int_\Theta p (D, \theta | M)d\theta}
                        =\frac{p(\theta | D, M) p(D|M)}{p (D | M)}
                        =p (\theta | D, M),
\end{equation*}
the posterior distributions of the parameters.

Now, let we consider the derivative of $\ln z(\beta)$.
\begin{align}
    \frac{d}{d\beta} \ln z(\beta) &= \frac{1}{z(\beta)}  
        \frac{d}{d\beta} z(\beta) \notag\\
    &= \frac{1}{z(\beta)} \frac{d}{d\beta} 
        \int_\Theta p (D | \theta, M)^\beta p(\theta | M) d\theta \notag\\
    \shortintertext{(using that $\frac{d}{dx} c^x = c^x \ln c$)}
    &= \frac{1}{z(\beta)} \int_\Theta p (D | \theta, M)^\beta 
        p(\theta | M) \ln p(D|\theta, M)d\theta \notag\\
    &= \int_\Theta \frac{p (D | \theta, M)^\beta p(\theta | M)}
                        {z(\beta)}
                    \ln p(D| \theta, M)d\theta \notag\\
    &=\int_\Theta p_\beta (\theta) \ln p (D | \theta, M)d\theta \notag\\ 
    &=\expectation_{p_\beta (\theta)} [\ln p(D|\theta, M)]. \label{eq:z_derivative}
\end{align}
And it is not hard to see that:
\begin{equation}
\begin{gathered}
    z (0) = \int_\Theta p (\theta | M)d\theta = 1 \\
    z (1) = \int_\Theta p (D, \theta | M)d\theta = p (D|M) 
    \label{eq:z_on_limits}
\end{gathered}
\end{equation}

Using equations~\ref{eq:z_on_limits} and equality~\ref{eq:z_derivative}
we can write that:
\begin{align}
    \int_0^1 \expectation_{p_\beta (\theta)} [\ln p(D|\theta, M)]d\beta 
    &= \int_0^1 \frac{d}{d\beta} \ln z(\beta) d\beta \notag \\
    &= \Big[\ln z(\beta)\Big]\bigg\rvert^1_0 \notag \\
    &= \ln p (D | M).
\end{align}
Then we have written an expression for the logarithm of the marginal
likelihood. This expression is still hard to be calculated analytically,
however from this equation we will be able to find estimators for
the logarithm of the marginal likelihood, and consequently for the
likelihood. To calculate this estimators, we will need to generate 
samples for a series of power posteriors of parameters, and this will
be explained in the next section.

% Subsection - Estimation of the Marginal Likelihood 
% -> We need to find samples of the posteriors
% -> Explain that we use the methodology of Xuan
% -> We use three Metropolis-Hastings
% -> A first burn-in step with jumps independent for each single 
% parameter. Adaptive Metropolis Hastings
% -> A second using a Variance-Covariance Matrix
% -> A third using populational MCMC
\subsection{Estimation of the Marginal Likelihood}


% ABC-SysBio
% Experiments comparing both approaches
